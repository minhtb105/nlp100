{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WWYP3hweVTpK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9bxZU8QVhcB",
        "outputId": "b15b5409-efab-4158-daaf-72071942c941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjOVmmlBXDYc",
        "outputId": "a678d7c9-194f-43cb-cd27-7cfb3202b301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "llkHjqNRV8tU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "train_data = pd.read_csv(r'/content/drive/MyDrive/data/train.txt', header=None, sep='\\t')\n",
        "train_data.columns = ['title', 'category']\n",
        "\n",
        "val_data = pd.read_csv(r'/content/drive/MyDrive/data/val.txt', header=None, sep='\\t')\n",
        "val_data.columns = ['title', 'category']\n",
        "\n",
        "test_data = pd.read_csv(r'/content/drive/MyDrive/data/test.txt', header=None, sep='\\t')\n",
        "test_data.columns = ['title', 'category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWYjLYxc7LRu"
      },
      "outputs": [],
      "source": [
        "def turning_words_into_numeric(df):\n",
        "    data = ' '.join(df['title'].tolist())\n",
        "    tokens = data.split()\n",
        "    counter = Counter(tokens).most_common(len(tokens))\n",
        "    title_int = {}\n",
        "    for i, (token, freq) in enumerate(counter):\n",
        "        if i == 0:\n",
        "            title_int[token] = 1\n",
        "        elif i == 1:\n",
        "            title_int[token] = 2\n",
        "        elif freq < 2:\n",
        "            title_int[token] = 0\n",
        "        else:\n",
        "            title_int[token] = i + 1\n",
        "\n",
        "    return title_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1nh2X9E_mng"
      },
      "outputs": [],
      "source": [
        "train_title_int = turning_words_into_numeric(train_data)\n",
        "\n",
        "train_title_int\n",
        "train_data['title_int_id'] = train_data['title'].apply(lambda title: [train_title_int[word] for word in title.split()])\n",
        "\n",
        "val_title_int = turning_words_into_numeric(val_data)\n",
        "val_data['title_int_id'] = val_data['title'].apply(lambda title: [val_title_int[word] for word in title.split()])\n",
        "\n",
        "test_title_int = turning_words_into_numeric(test_data)\n",
        "test_data['title_int_id'] = test_data['title'].apply(lambda title: [test_title_int[word] for word in title.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPg4qNkCncaI"
      },
      "outputs": [],
      "source": [
        "def pad_sequence(data, max_length):\n",
        "    padded_data = []\n",
        "    for sample in data:\n",
        "        if len(sample) < max_length:\n",
        "            padded_sample = sample + [0] * (max_length - len(sample))  # Padding with zeros\n",
        "            padded_data.append(padded_sample)\n",
        "        else:\n",
        "            padded_data.append(sample[:max_length])  # Truncate if longer than max_length\n",
        "    return padded_data\n",
        "\n",
        "\n",
        "max_length = max(max(len(sample) for sample in train_data['title_int_id']),\n",
        "                 max(len(sample) for sample in val_data['title_int_id']),\n",
        "                 max(len(sample) for sample in test_data['title_int_id']))\n",
        "\n",
        "train_data['title_int_id'] = pad_sequence(train_data['title_int_id'].values, max_length)\n",
        "val_data['title_int_id'] = pad_sequence(val_data['title_int_id'].values, max_length)\n",
        "test_data['title_int_id'] = pad_sequence(test_data['title_int_id'].values, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McCFdZ89DIL_"
      },
      "outputs": [],
      "source": [
        "class NewsTitleDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.X = data['title_int_id'].values\n",
        "        self.y = data['category'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4Q1EZimk7Sh"
      },
      "outputs": [],
      "source": [
        "train_dataset = NewsTitleDataset(train_data)\n",
        "val_dataset = NewsTitleDataset(val_data)\n",
        "test_dataset = NewsTitleDataset(test_data)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDmJCYzLoUQp"
      },
      "outputs": [],
      "source": [
        "class NewsClassify(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes=2):\n",
        "        super(NewsClassify,  self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        output, hidden = self.rnn(embed)\n",
        "        out = self.fc(output[:, -1, :])\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY_DGiTy1NUA"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(train_title_int)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 50\n",
        "model = NewsClassify(vocab_size + 1, embedding_dim, hidden_dim, 4)\n",
        "\n",
        "# for features, labels in train_dataloader:\n",
        "#     y = model(features)\n",
        "#     print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq7aNxCu2MOG",
        "outputId": "5d4edb52-d73a-40da-b004-1d5fe1dd23d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 2, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 3, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 4, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 5, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 6, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 7, Train Accuracy: 0.42803969979286194, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.40229007601737976\n",
            "Epoch 8, Train Accuracy: 0.42546287178993225, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.4030534327030182\n",
            "Epoch 9, Train Accuracy: 0.42546287178993225, Dev Accuracy: 0.40229007601737976, Test Accuracy: 0.4030534327030182\n",
            "Epoch 10, Train Accuracy: 0.4197365939617157, Dev Accuracy: 0.40458014607429504, Test Accuracy: 0.41297709941864014\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD(params=model.parameters(), lr=0.005)\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for features, labels in train_dataloader:\n",
        "        outputs = model(features)\n",
        "        loss = criteria(outputs, labels.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    train_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in train_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            train_acc(predicts, labels.squeeze())\n",
        "\n",
        "    train_accuracy = train_acc.compute()\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in val_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            val_acc(predicts, labels.squeeze())\n",
        "\n",
        "    val_accuracy = val_acc.compute()\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    test_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            test_acc(predicts, labels.squeeze())\n",
        "\n",
        "    test_accuracy = test_acc.compute()\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f\"Epoch {epoch+1}, Train Accuracy: {train_accuracy}, Dev Accuracy: {val_accuracy}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdmiCS47zjmx"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word_vectors = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/data/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzf91I2p-dH8"
      },
      "outputs": [],
      "source": [
        "word_to_index = word_vectors.key_to_index\n",
        "train_data['word_embed_id'] = train_data['title'].apply(lambda title: [word_to_index.get(word, 0) for word in title.split()])\n",
        "val_data['word_embed_id'] = val_data['title'].apply(lambda title: [word_to_index.get(word, 0) for word in title.split()])\n",
        "test_data['word_embed_id'] = test_data['title'].apply(lambda title: [word_to_index.get(word, 0) for word in title.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDU0SYd__-d8"
      },
      "outputs": [],
      "source": [
        "train_data['word_embed_id'] = pad_sequence(train_data['word_embed_id'].values, max_length)\n",
        "val_data['word_embed_id'] = pad_sequence(val_data['word_embed_id'].values, max_length)\n",
        "test_data['word_embed_id'] = pad_sequence(test_data['word_embed_id'].values, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlbTgsQD7lW1"
      },
      "outputs": [],
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super(NewsDataset, self).__init__()\n",
        "        self.X = data['word_embed_id']\n",
        "        self.y = data['category']\n",
        "        self.word_to_index = word_to_index\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor([self.y[idx]], dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UBZVNgC9mw-"
      },
      "outputs": [],
      "source": [
        "train_dataset = NewsDataset(train_data)\n",
        "val_dataset = NewsDataset(val_data)\n",
        "test_dataset = NewsDataset(test_data)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, num_workers=2)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y573-ZHLDNzc"
      },
      "outputs": [],
      "source": [
        "class NewsClassify(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pretrained_word2vec: None, num_classes=2, num_layers=2):\n",
        "        super(NewsClassify,  self).__init__()\n",
        "        if pretrained_word2vec != None:\n",
        "            weights = torch.FloatTensor(pretrained_word2vec.vectors)\n",
        "            self.embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(2 * hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        output, hidden = self.rnn(embed)\n",
        "\n",
        "        out = self.fc(output[:, -1, :])\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9XW7p-ODq7e"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(word_to_index)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 50\n",
        "model = NewsClassify(vocab_size + 1, embedding_dim, hidden_dim, word_vectors, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bVPZXZEDfHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0401fe6e-8769-47ef-843f-b10ee00b2303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Accuracy: 0.42574918270111084, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 2, Train Accuracy: 0.42574918270111084, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 3, Train Accuracy: 0.42574918270111084, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 4, Train Accuracy: 0.42574918270111084, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 5, Train Accuracy: 0.42574918270111084, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 6, Train Accuracy: 0.42574918270111084, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 7, Train Accuracy: 0.42584463953971863, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 8, Train Accuracy: 0.42584463953971863, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 9, Train Accuracy: 0.42584463953971863, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n",
            "Epoch 10, Train Accuracy: 0.42584463953971863, Dev Accuracy: 0.4068702161312103, Test Accuracy: 0.4038167893886566\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD(params=model.parameters(), lr=0.005)\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for features, labels in train_dataloader:\n",
        "        outputs = model(features)\n",
        "        loss = criteria(outputs, labels.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    train_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in train_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            train_acc(predicts, labels.squeeze())\n",
        "\n",
        "    train_accuracy = train_acc.compute()\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in val_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            val_acc(predicts, labels.squeeze())\n",
        "\n",
        "    val_accuracy = val_acc.compute()\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    test_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            test_acc(predicts, labels.squeeze())\n",
        "\n",
        "    test_accuracy = test_acc.compute()\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f\"Epoch {epoch+1}, Train Accuracy: {train_accuracy}, Dev Accuracy: {val_accuracy}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrXd7mETa96Q"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, pretrained_word2vec: None):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.dropout = nn.Dropout(0.9)\n",
        "        if pretrained_word2vec != None:\n",
        "            weights = torch.FloatTensor(pretrained_word2vec.vectors)\n",
        "            self.embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.conv = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=3, padding=1, bias=False)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
        "        self.fc = nn.Linear(hidden_dim, 10)\n",
        "        self.fc2 = nn.Linear(10, 10)\n",
        "        self.fc3 = nn.Linear(10, 10)\n",
        "        self.fc4 = nn.Linear(10, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout(self.embedding(x)) # shape: (batch_size, seq_len, embedding_dim)\n",
        "        embedded = embedded.permute(0, 2, 1) # shape: (batch_size, embedding_dim, seq_len)\n",
        "        conv_out = self.conv(embedded)  # shape: (batch_size, hidden_dim, seq_len)\n",
        "        pooled = self.pool(conv_out) # shape: (batch_size, hidden_dim, seq_len)\n",
        "        pooled, _ = torch.max(pooled, dim=2) # shape: (batch_size, hidden_dim)\n",
        "        output = self.fc(pooled)  # shape: (batch_size, num_classes)\n",
        "        output = self.fc2(output)\n",
        "        output = self.fc3(output)\n",
        "        output = self.fc4(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLtr7vECSPu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00da24e1-aa4f-4f54-f872-77b97627468f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Accuracy: 0.6953617334365845, Dev Accuracy: 0.676335871219635, Test Accuracy: 0.7099236845970154\n",
            "Epoch 2, Train Accuracy: 0.7439396977424622, Dev Accuracy: 0.7221373915672302, Test Accuracy: 0.743511438369751\n",
            "Epoch 3, Train Accuracy: 0.7543424367904663, Dev Accuracy: 0.7312977313995361, Test Accuracy: 0.7526717782020569\n",
            "Epoch 4, Train Accuracy: 0.7728574275970459, Dev Accuracy: 0.7526717782020569, Test Accuracy: 0.7687022686004639\n",
            "Epoch 5, Train Accuracy: 0.7731437087059021, Dev Accuracy: 0.7534351348876953, Test Accuracy: 0.7641221284866333\n",
            "Epoch 6, Train Accuracy: 0.7807787656784058, Dev Accuracy: 0.761832058429718, Test Accuracy: 0.7740458250045776\n",
            "Epoch 7, Train Accuracy: 0.7861233353614807, Dev Accuracy: 0.7679389119148254, Test Accuracy: 0.7793893218040466\n",
            "Epoch 8, Train Accuracy: 0.7844054102897644, Dev Accuracy: 0.767175555229187, Test Accuracy: 0.7763358950614929\n",
            "Epoch 9, Train Accuracy: 0.7924222350120544, Dev Accuracy: 0.7740458250045776, Test Accuracy: 0.7877862453460693\n",
            "Epoch 10, Train Accuracy: 0.8004390001296997, Dev Accuracy: 0.7770992517471313, Test Accuracy: 0.7984732985496521\n",
            "Epoch 11, Train Accuracy: 0.8091238737106323, Dev Accuracy: 0.7870228886604309, Test Accuracy: 0.8022900819778442\n",
            "Epoch 12, Train Accuracy: 0.8122733235359192, Dev Accuracy: 0.7984732985496521, Test Accuracy: 0.8091602921485901\n",
            "Epoch 13, Train Accuracy: 0.8178087472915649, Dev Accuracy: 0.7977099418640137, Test Accuracy: 0.8099236488342285\n",
            "Epoch 14, Train Accuracy: 0.8138957619667053, Dev Accuracy: 0.790839672088623, Test Accuracy: 0.8106870055198669\n",
            "Epoch 15, Train Accuracy: 0.82181715965271, Dev Accuracy: 0.8015267252922058, Test Accuracy: 0.8175572752952576\n",
            "Epoch 16, Train Accuracy: 0.8159953951835632, Dev Accuracy: 0.7877862453460693, Test Accuracy: 0.8145037889480591\n",
            "Epoch 17, Train Accuracy: 0.8191449046134949, Dev Accuracy: 0.7992366552352905, Test Accuracy: 0.818320631980896\n",
            "Epoch 18, Train Accuracy: 0.8238213658332825, Dev Accuracy: 0.8007633686065674, Test Accuracy: 0.8152672052383423\n",
            "Epoch 19, Train Accuracy: 0.8237258791923523, Dev Accuracy: 0.7969465851783752, Test Accuracy: 0.8160305619239807\n",
            "Epoch 20, Train Accuracy: 0.8256346583366394, Dev Accuracy: 0.8015267252922058, Test Accuracy: 0.8167939186096191\n",
            "Epoch 21, Train Accuracy: 0.8324107527732849, Dev Accuracy: 0.8030534386634827, Test Accuracy: 0.8229007720947266\n",
            "Epoch 22, Train Accuracy: 0.8363237380981445, Dev Accuracy: 0.8083969354629517, Test Accuracy: 0.8282442688941956\n",
            "Epoch 23, Train Accuracy: 0.8338423371315002, Dev Accuracy: 0.8038167953491211, Test Accuracy: 0.8229007720947266\n",
            "Epoch 24, Train Accuracy: 0.8341286778450012, Dev Accuracy: 0.8091602921485901, Test Accuracy: 0.8267175555229187\n",
            "Epoch 25, Train Accuracy: 0.8388051390647888, Dev Accuracy: 0.8152672052383423, Test Accuracy: 0.8297709822654724\n",
            "Epoch 26, Train Accuracy: 0.8296430706977844, Dev Accuracy: 0.8076335787773132, Test Accuracy: 0.818320631980896\n",
            "Epoch 27, Train Accuracy: 0.8369917869567871, Dev Accuracy: 0.8114503622055054, Test Accuracy: 0.823664128780365\n",
            "Epoch 28, Train Accuracy: 0.8381370306015015, Dev Accuracy: 0.8129770755767822, Test Accuracy: 0.8244274854660034\n",
            "Epoch 29, Train Accuracy: 0.8311700820922852, Dev Accuracy: 0.8083969354629517, Test Accuracy: 0.818320631980896\n",
            "Epoch 30, Train Accuracy: 0.8418591618537903, Dev Accuracy: 0.8160305619239807, Test Accuracy: 0.8297709822654724\n",
            "Epoch 31, Train Accuracy: 0.835655689239502, Dev Accuracy: 0.8160305619239807, Test Accuracy: 0.8229007720947266\n",
            "Epoch 32, Train Accuracy: 0.8432906866073608, Dev Accuracy: 0.8198473453521729, Test Accuracy: 0.8328244090080261\n",
            "Epoch 33, Train Accuracy: 0.8451040387153625, Dev Accuracy: 0.8122137188911438, Test Accuracy: 0.8320610523223877\n",
            "Epoch 34, Train Accuracy: 0.8437678813934326, Dev Accuracy: 0.8122137188911438, Test Accuracy: 0.8297709822654724\n",
            "Epoch 35, Train Accuracy: 0.845199465751648, Dev Accuracy: 0.8229007720947266, Test Accuracy: 0.8374046087265015\n",
            "Epoch 36, Train Accuracy: 0.844913125038147, Dev Accuracy: 0.8198473453521729, Test Accuracy: 0.8358778357505798\n",
            "Epoch 37, Train Accuracy: 0.8389959931373596, Dev Accuracy: 0.8045801520347595, Test Accuracy: 0.8297709822654724\n",
            "Epoch 38, Train Accuracy: 0.8410956263542175, Dev Accuracy: 0.8122137188911438, Test Accuracy: 0.8335877656936646\n",
            "Epoch 39, Train Accuracy: 0.8486352562904358, Dev Accuracy: 0.8229007720947266, Test Accuracy: 0.8320610523223877\n",
            "Epoch 40, Train Accuracy: 0.8417636752128601, Dev Accuracy: 0.8145037889480591, Test Accuracy: 0.8282442688941956\n",
            "Epoch 41, Train Accuracy: 0.8374689817428589, Dev Accuracy: 0.8152672052383423, Test Accuracy: 0.823664128780365\n",
            "Epoch 42, Train Accuracy: 0.8462492823600769, Dev Accuracy: 0.8190839886665344, Test Accuracy: 0.8328244090080261\n",
            "Epoch 43, Train Accuracy: 0.8482534885406494, Dev Accuracy: 0.8244274854660034, Test Accuracy: 0.834351122379303\n",
            "Epoch 44, Train Accuracy: 0.8425272107124329, Dev Accuracy: 0.8190839886665344, Test Accuracy: 0.8320610523223877\n",
            "Epoch 45, Train Accuracy: 0.8473945260047913, Dev Accuracy: 0.8206107020378113, Test Accuracy: 0.8282442688941956\n",
            "Epoch 46, Train Accuracy: 0.8496850728988647, Dev Accuracy: 0.8229007720947266, Test Accuracy: 0.8335877656936646\n",
            "Epoch 47, Train Accuracy: 0.8514983654022217, Dev Accuracy: 0.8244274854660034, Test Accuracy: 0.8381679654121399\n",
            "Epoch 48, Train Accuracy: 0.8493987321853638, Dev Accuracy: 0.8282442688941956, Test Accuracy: 0.8389313220977783\n",
            "Epoch 49, Train Accuracy: 0.844149649143219, Dev Accuracy: 0.818320631980896, Test Accuracy: 0.834351122379303\n",
            "Epoch 50, Train Accuracy: 0.8480626344680786, Dev Accuracy: 0.8213740587234497, Test Accuracy: 0.8374046087265015\n",
            "Epoch 51, Train Accuracy: 0.8524527549743652, Dev Accuracy: 0.8229007720947266, Test Accuracy: 0.8389313220977783\n",
            "Epoch 52, Train Accuracy: 0.8523573279380798, Dev Accuracy: 0.8244274854660034, Test Accuracy: 0.8381679654121399\n",
            "Epoch 53, Train Accuracy: 0.8459629416465759, Dev Accuracy: 0.8198473453521729, Test Accuracy: 0.8320610523223877\n",
            "Epoch 54, Train Accuracy: 0.8525481820106506, Dev Accuracy: 0.8221374154090881, Test Accuracy: 0.8335877656936646\n",
            "Epoch 55, Train Accuracy: 0.8524527549743652, Dev Accuracy: 0.8267175555229187, Test Accuracy: 0.834351122379303\n",
            "Epoch 56, Train Accuracy: 0.8505439758300781, Dev Accuracy: 0.8206107020378113, Test Accuracy: 0.8335877656936646\n",
            "Epoch 57, Train Accuracy: 0.8490169644355774, Dev Accuracy: 0.8229007720947266, Test Accuracy: 0.8312976956367493\n",
            "Epoch 58, Train Accuracy: 0.8521664142608643, Dev Accuracy: 0.8244274854660034, Test Accuracy: 0.8297709822654724\n",
            "Epoch 59, Train Accuracy: 0.853693425655365, Dev Accuracy: 0.8282442688941956, Test Accuracy: 0.8389313220977783\n",
            "Epoch 60, Train Accuracy: 0.8531208038330078, Dev Accuracy: 0.8259541988372803, Test Accuracy: 0.8320610523223877\n",
            "Epoch 61, Train Accuracy: 0.8586562275886536, Dev Accuracy: 0.8297709822654724, Test Accuracy: 0.8358778357505798\n",
            "Epoch 62, Train Accuracy: 0.8516892790794373, Dev Accuracy: 0.8267175555229187, Test Accuracy: 0.8305343389511108\n",
            "Epoch 63, Train Accuracy: 0.8555067777633667, Dev Accuracy: 0.8259541988372803, Test Accuracy: 0.8366411924362183\n",
            "Epoch 64, Train Accuracy: 0.8545523881912231, Dev Accuracy: 0.8282442688941956, Test Accuracy: 0.8396946787834167\n",
            "Epoch 65, Train Accuracy: 0.8558885455131531, Dev Accuracy: 0.823664128780365, Test Accuracy: 0.8396946787834167\n",
            "Epoch 66, Train Accuracy: 0.8585608005523682, Dev Accuracy: 0.8312976956367493, Test Accuracy: 0.841984748840332\n",
            "Epoch 67, Train Accuracy: 0.8521664142608643, Dev Accuracy: 0.8259541988372803, Test Accuracy: 0.834351122379303\n",
            "Epoch 68, Train Accuracy: 0.8545523881912231, Dev Accuracy: 0.8282442688941956, Test Accuracy: 0.841984748840332\n",
            "Epoch 69, Train Accuracy: 0.8577972650527954, Dev Accuracy: 0.8267175555229187, Test Accuracy: 0.8374046087265015\n",
            "Epoch 70, Train Accuracy: 0.8580836057662964, Dev Accuracy: 0.8282442688941956, Test Accuracy: 0.8412213921546936\n",
            "Epoch 71, Train Accuracy: 0.856652021408081, Dev Accuracy: 0.829007625579834, Test Accuracy: 0.834351122379303\n",
            "Epoch 72, Train Accuracy: 0.8580836057662964, Dev Accuracy: 0.829007625579834, Test Accuracy: 0.8366411924362183\n",
            "Epoch 73, Train Accuracy: 0.857988178730011, Dev Accuracy: 0.8274809122085571, Test Accuracy: 0.8389313220977783\n",
            "Epoch 74, Train Accuracy: 0.8545523881912231, Dev Accuracy: 0.8259541988372803, Test Accuracy: 0.8335877656936646\n",
            "Epoch 75, Train Accuracy: 0.8541706204414368, Dev Accuracy: 0.8267175555229187, Test Accuracy: 0.8351144790649414\n",
            "Epoch 76, Train Accuracy: 0.8605650067329407, Dev Accuracy: 0.834351122379303, Test Accuracy: 0.8412213921546936\n",
            "Epoch 77, Train Accuracy: 0.8559839725494385, Dev Accuracy: 0.8328244090080261, Test Accuracy: 0.834351122379303\n",
            "Epoch 78, Train Accuracy: 0.8598014712333679, Dev Accuracy: 0.8297709822654724, Test Accuracy: 0.8396946787834167\n",
            "Epoch 79, Train Accuracy: 0.857988178730011, Dev Accuracy: 0.829007625579834, Test Accuracy: 0.8396946787834167\n",
            "Epoch 80, Train Accuracy: 0.863046407699585, Dev Accuracy: 0.8297709822654724, Test Accuracy: 0.841984748840332\n",
            "Epoch 81, Train Accuracy: 0.8607558608055115, Dev Accuracy: 0.8312976956367493, Test Accuracy: 0.8427481055259705\n",
            "Epoch 82, Train Accuracy: 0.8590379953384399, Dev Accuracy: 0.8274809122085571, Test Accuracy: 0.834351122379303\n",
            "Epoch 83, Train Accuracy: 0.8594197630882263, Dev Accuracy: 0.8320610523223877, Test Accuracy: 0.8351144790649414\n",
            "Epoch 84, Train Accuracy: 0.8628554940223694, Dev Accuracy: 0.8312976956367493, Test Accuracy: 0.8412213921546936\n",
            "Epoch 85, Train Accuracy: 0.8618056774139404, Dev Accuracy: 0.8297709822654724, Test Accuracy: 0.8320610523223877\n",
            "Epoch 86, Train Accuracy: 0.8604695796966553, Dev Accuracy: 0.829007625579834, Test Accuracy: 0.8404580354690552\n",
            "Epoch 87, Train Accuracy: 0.8556976318359375, Dev Accuracy: 0.8282442688941956, Test Accuracy: 0.8335877656936646\n",
            "Epoch 88, Train Accuracy: 0.856938362121582, Dev Accuracy: 0.8305343389511108, Test Accuracy: 0.8396946787834167\n",
            "Epoch 89, Train Accuracy: 0.856652021408081, Dev Accuracy: 0.8305343389511108, Test Accuracy: 0.8381679654121399\n",
            "Epoch 90, Train Accuracy: 0.8553159236907959, Dev Accuracy: 0.8229007720947266, Test Accuracy: 0.8358778357505798\n",
            "Epoch 91, Train Accuracy: 0.8595151901245117, Dev Accuracy: 0.8305343389511108, Test Accuracy: 0.841984748840332\n",
            "Epoch 92, Train Accuracy: 0.8491124510765076, Dev Accuracy: 0.8213740587234497, Test Accuracy: 0.834351122379303\n",
            "Epoch 93, Train Accuracy: 0.8605650067329407, Dev Accuracy: 0.8274809122085571, Test Accuracy: 0.8389313220977783\n",
            "Epoch 94, Train Accuracy: 0.8643825054168701, Dev Accuracy: 0.8374046087265015, Test Accuracy: 0.8381679654121399\n",
            "Epoch 95, Train Accuracy: 0.8605650067329407, Dev Accuracy: 0.8305343389511108, Test Accuracy: 0.841984748840332\n",
            "Epoch 96, Train Accuracy: 0.8549341559410095, Dev Accuracy: 0.8244274854660034, Test Accuracy: 0.8412213921546936\n",
            "Epoch 97, Train Accuracy: 0.8601832389831543, Dev Accuracy: 0.8297709822654724, Test Accuracy: 0.8427481055259705\n",
            "Epoch 98, Train Accuracy: 0.8580836057662964, Dev Accuracy: 0.829007625579834, Test Accuracy: 0.8374046087265015\n",
            "Epoch 99, Train Accuracy: 0.8554113507270813, Dev Accuracy: 0.8259541988372803, Test Accuracy: 0.8396946787834167\n",
            "Epoch 100, Train Accuracy: 0.8580836057662964, Dev Accuracy: 0.8251908421516418, Test Accuracy: 0.8435114622116089\n"
          ]
        }
      ],
      "source": [
        "model = CNNModel(vocab_size, embedding_dim, hidden_dim, 4, word_vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.006, momentum=0.9, weight_decay=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, targets in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    train_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in train_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            train_acc(predicts, labels.squeeze())\n",
        "\n",
        "    train_accuracy = train_acc.compute()\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in val_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            val_acc(predicts, labels.squeeze())\n",
        "\n",
        "    val_accuracy = val_acc.compute()\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    test_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_dataloader:\n",
        "            outputs = model(features)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            test_acc(predicts, labels.squeeze())\n",
        "\n",
        "    test_accuracy = test_acc.compute()\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f\"Epoch {epoch+1}, Train Accuracy: {train_accuracy}, Dev Accuracy: {val_accuracy}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PjXHYP_R-Zy6"
      },
      "outputs": [],
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        title = self.data.iloc[idx]['title']\n",
        "        category = self.data.iloc[idx]['category']\n",
        "\n",
        "        encoding = self.tokenizer(title, truncation=True, max_length=self.max_length, padding='max_length', return_tensors='pt')\n",
        "        input_ids = encoding['input_ids'].squeeze(0)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "        return input_ids, attention_mask, category"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_dataset = NewsDataset(train_data, tokenizer, max_length=100)\n",
        "val_dataset = NewsDataset(val_data, tokenizer, max_length=100)\n",
        "test_dataset = NewsDataset(test_data, tokenizer, max_length=100)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 128, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = 128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 128, shuffle=True)"
      ],
      "metadata": {
        "id": "7SkNN0MZQdbz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sNX5J0S1Lk9"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "class NewsClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(NewsClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        return linear_output\n",
        "\n",
        "model = NewsClassifier(num_classes=4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_ids, attention_mask, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    train_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, labels in train_dataloader:\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            train_acc(predicts, labels)\n",
        "\n",
        "    train_accuracy = train_acc.compute()\n",
        "\n",
        "    val_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, labels in val_dataloader:\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            val_acc(predicts, labels)\n",
        "\n",
        "    val_accuracy = val_acc.compute()\n",
        "\n",
        "    test_acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, labels in test_dataloader:\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predicts = torch.argmax(outputs, dim=1)\n",
        "            test_acc(predicts, labels)\n",
        "\n",
        "    test_accuracy = test_acc.compute()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Accuracy: {train_accuracy}, Dev Accuracy: {val_accuracy}, Test Accuracy: {test_accuracy}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}